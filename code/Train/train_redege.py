import sys
import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import time

# --- 1. è·¯å¾„å¯¼èˆª ---
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(current_dir))

from data.rededge_dataset import MyDatasetInterface
from MODEL.model import MSFusionUNet as MSFusionModel

class MSFusion(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.model = MSFusionModel(in_channels=in_channels, num_classes=num_classes, norm_type='bn', dilation=2)
    def forward(self, x):
        return self.model(x)

def get_param(p):
    return p[0] if isinstance(p, list) else p

def train():
    # --- åŠ è½½é…ç½® ---
    config_path = os.path.join(os.path.dirname(current_dir), "Params/Eschikon/Esc_unet_v2.yaml")
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)['parameters']

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # --- æ•°æ®å‡†å¤‡ ---
    ds_config = config['dataset']
    data_interface = MyDatasetInterface(ds_config)
    data_interface.build_data_loaders()
    
    # --- è‡ªåŠ¨é€‚é…é€šé“ä¸ç±»åˆ« ---
    channels = get_param(ds_config['channels'])
    in_channels = 0
    for c in channels:
        in_channels += 3 if c.lower() == 'rgb' else 1
    
    num_classes = get_param(ds_config['num_classes'])
    print(f"ğŸ“Š æ¨¡å‹é…ç½®: è¾“å…¥ {in_channels} é€šé“ | è¾“å‡º {num_classes} åˆ†ç±»")

    # --- æ¨¡å‹ä¸ä¼˜åŒ–å™¨ ---
    model = MSFusion(in_channels=in_channels, num_classes=num_classes).to(device)
    
    # é’ˆå¯¹ç±»åˆ«ä¸å¹³è¡¡ï¼Œå¯ä»¥è€ƒè™‘ä¸º CrossEntropy å¢åŠ æƒé‡ï¼Œç›®å‰ä½¿ç”¨é»˜è®¤
    criterion = nn.CrossEntropyLoss()
    
    tr_config = config['train_params']
    optimizer = optim.Adam(model.parameters(), lr=get_param(tr_config['initial_lr']))
    
    epochs = get_param(tr_config['max_epochs'])
    best_val_loss = float('inf')

    # --- è®­ç»ƒå¾ªç¯ ---
    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        pbar = tqdm(data_interface.train_loader, desc=f"Epoch {epoch+1}/{epochs}")
        
        for imgs, masks in pbar:
            imgs, masks = imgs.to(device), masks.to(device)
            
            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, masks)
            
            if torch.isnan(loss):
                print("âŒ è­¦å‘Š: Loss ä¸º NaNï¼Œè·³è¿‡è¯¥ Batch")
                continue
                
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            pbar.set_postfix({'loss': f"{loss.item():.4f}"})

        avg_train = train_loss / len(data_interface.train_loader)
        
        # éªŒè¯é€»è¾‘
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for imgs, masks in data_interface.val_loader:
                imgs, masks = imgs.to(device), masks.to(device)
                outputs = model(imgs)
                val_loss += criterion(outputs, masks).item()
        
        avg_val = val_loss / len(data_interface.val_loader)
        print(f"ğŸ“‰ Epoch {epoch+1}: Train Loss {avg_train:.4f} | Val Loss {avg_val:.4f}")

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if avg_val < best_val_loss:
            best_val_loss = avg_val
            save_path = "best_model_suger.pth"
            torch.save(model.state_dict(), save_path)
            print(f"ğŸŒŸ å·²æ›´æ–°æœ€ä¼˜æ¨¡å‹: {save_path}")

if __name__ == '__main__':
    train()
