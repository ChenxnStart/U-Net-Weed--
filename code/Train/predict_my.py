import os
import torch
import cv2
import numpy as np
import sys

# --- 1. è·¯å¾„é…ç½® ---
# è‡ªåŠ¨æ‰¾åˆ°ä¸Šçº§ç›®å½•ä»¥ä¾¿å¯¼å…¥æ¨¡å‹
current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)
sys.path.append(os.path.dirname(current_dir))

from MODEL.model import MSFusionUNet as MSFusionModel

# ç®€å•çš„æ¨¡å‹åŒ…è£…å™¨ (å¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´)
class MSFusion(torch.nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.model = MSFusionModel(in_channels=in_channels, num_classes=num_classes, norm_type='bn', dilation=2)
    def forward(self, x):
        return self.model(x)

def predict():
    # ================= é…ç½®åŒºåŸŸ =================
    # 1. æ¨¡å‹è·¯å¾„
    model_path = "best_model.pth" 
    
    # 2. æµ‹è¯•å›¾ç‰‡çš„åŸºç¡€è·¯å¾„ (RGBæ–‡ä»¶å¤¹)
    # è¯·ä¿®æ”¹ä¸ºæ‚¨ç¡¬ç›˜ä¸Šçš„çœŸå®è·¯å¾„ï¼Œä¾‹å¦‚ dataset/test/rgb/xxx.png
    # è¿™é‡Œæˆ‘ä»¬è‡ªåŠ¨å» dataset/val/rgb é‡Œéšä¾¿æ‰¾ä¸€å¼ æ¥æµ‹
    base_dataset_dir = "/media/cclsol/df07c0f4-31b8-4090-8a4a-8c254d91c123/ch/MSU-Net/dataset/val"
    
    # 3. å‚æ•°é…ç½® (å¿…é¡»å’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´)
    img_size = 512
    num_classes = 2
    # æ‚¨çš„è®­ç»ƒç”¨äº†7é€šé“: rgb, nir, re, red, green
    channels_config = ['rgb', 'nir', 're', 'red', 'green'] 
    # ===========================================

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}")

    # --- 1. åŠ è½½æ¨¡å‹ ---
    in_channels = 0
    for c in channels_config:
        in_channels += 3 if c == 'rgb' else 1
        
    print(f"åˆå§‹åŒ–æ¨¡å‹ (è¾“å…¥é€šé“: {in_channels}, ç±»åˆ«: {num_classes})...")
    model = MSFusion(in_channels=in_channels, num_classes=num_classes)
    
    # åŠ è½½æƒé‡
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        return
        
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

    # --- 2. å¯»æ‰¾æµ‹è¯•å›¾ç‰‡ ---
    rgb_dir = os.path.join(base_dataset_dir, 'rgb')
    if not os.path.exists(rgb_dir):
        print(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•ç›®å½•: {rgb_dir}")
        return

    # éšä¾¿æ‹¿ç¬¬ä¸€å¼ å›¾æ¥æµ‹
    test_files = [f for f in os.listdir(rgb_dir) if f.endswith(('.png', '.tif', '.jpg'))]
    if not test_files:
        print("âŒ æµ‹è¯•ç›®å½•ä¸‹æ²¡æœ‰å›¾ç‰‡")
        return
    
    filename = test_files[0] # å–ç¬¬ä¸€å¼ 
    file_stem = os.path.splitext(filename)[0]
    print(f"æ­£åœ¨é¢„æµ‹å›¾ç‰‡: {filename} ...")

    # --- 3. è¯»å–å¹¶ç»„åˆå¤šé€šé“æ•°æ® ---
    data_list = []
    try:
        for channel in channels_config:
            # è‡ªåŠ¨å¯»æ‰¾å¯¹åº”æ–‡ä»¶å¤¹ (rgb, nir, re...)
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ‰€æœ‰æ–‡ä»¶å¤¹éƒ½åœ¨ val ç›®å½•ä¸‹ï¼Œä¸”æ–‡ä»¶å(stem)ä¸€è‡´
            target_folder = os.path.join(base_dataset_dir, channel.lower())
            
            # å°è¯•æ‰¾ .tif æˆ– .png
            found_path = None
            for ext in ['.tif', '.png', '.jpg']:
                path = os.path.join(target_folder, file_stem + ext)
                if os.path.exists(path):
                    found_path = path
                    break
            
            if not found_path:
                print(f"âŒ ç¼ºå°‘é€šé“æ–‡ä»¶: {channel}/{file_stem}")
                return

            img = cv2.imread(found_path, cv2.IMREAD_UNCHANGED)
            
            if channel == 'rgb':
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            if img.ndim == 2: img = img[:, :, np.newaxis]
            data_list.append(img)
            
    except Exception as e:
        print(f"è¯»å–å›¾ç‰‡å‡ºé”™: {e}")
        return

    # ç»„åˆ
    combined_img = np.concatenate(data_list, axis=2)
    
    # Resize & Normalize
    original_h, original_w = combined_img.shape[:2]
    combined_img = cv2.resize(combined_img, (img_size, img_size), interpolation=cv2.INTER_LINEAR)
    if combined_img.ndim == 2: combined_img = combined_img[:, :, np.newaxis]
    
    combined_img = combined_img.astype('float32')
    if combined_img.max() > 255: combined_img /= 65535.0
    else: combined_img /= 255.0

    # è½¬ Tensor
    input_tensor = torch.from_numpy(combined_img).permute(2, 0, 1).unsqueeze(0).to(device)

    # --- 4. é¢„æµ‹ ---
    with torch.no_grad():
        output = model(input_tensor)
        # å–æœ€å¤§æ¦‚ç‡çš„ç±»åˆ« (Argmax)
        pred_mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

    # --- 5. ä¿å­˜ç»“æœ ---
    # æŠŠé¢„æµ‹ç»“æœæ”¾å¤§å›åŸå§‹å°ºå¯¸
    pred_mask = pred_mask.astype(np.uint8)
    pred_mask = cv2.resize(pred_mask, (original_w, original_h), interpolation=cv2.INTER_NEAREST)
    
    # ä¸ºäº†å¯è§†åŒ–ï¼ŒæŠŠ 0/1 å˜æˆ 0/255 (é»‘ç™½)
    pred_mask = pred_mask * 255

    save_name = f"pred_{file_stem}.png"
    cv2.imwrite(save_name, pred_mask)
    print(f"ğŸ‰ é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜ä¸º: {save_name}")
    print("è¯·æ‰“å¼€è¿™ä¸ªå›¾ç‰‡çœ‹çœ‹æ•ˆæœå¦‚ä½•ï¼(ç™½è‰²æ˜¯ç›®æ ‡ï¼Œé»‘è‰²æ˜¯èƒŒæ™¯)")

if __name__ == '__main__':
    predict()
