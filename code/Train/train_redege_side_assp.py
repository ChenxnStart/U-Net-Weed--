import os
import sys
import logging
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from datetime import datetime
import torch.optim as optim

# --- 1. è·¯å¾„ä¿®å¤ (é˜²æ­¢ ModuleNotFoundError) ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

# --- 2. å¼•å…¥ä¹‹å‰çš„ Dataset å’Œ Model ---
# ç¡®ä¿æ–‡ä»¶åå’Œç±»åä¸æˆ‘ä»¬ä¹‹å‰ä¿®å¥½çš„ä¸€è‡´
from data.rededge_dataset import EschikonDataset 
from MODEL.model import MSFusionUNet as MSFusionModel

# ==========================================
# ğŸ“Š 1. è¯„ä¼°å·¥å…·ç±» (è®¡ç®— mIoU å’Œ F1)
# ==========================================
class Evaluator(object):
    def __init__(self, num_class):
        self.num_class = num_class
        self.confusion_matrix = np.zeros((self.num_class,)*2)

    def pixel_accuracy(self):
        return np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()

    def mean_intersection_over_union(self):
        miou = np.diag(self.confusion_matrix) / (
            np.sum(self.confusion_matrix, axis=1) + 
            np.sum(self.confusion_matrix, axis=0) - 
            np.diag(self.confusion_matrix) + 1e-6
        )
        return np.nanmean(miou), miou

    def f1_score(self):
        TP = np.diag(self.confusion_matrix)
        FP = np.sum(self.confusion_matrix, axis=0) - TP
        FN = np.sum(self.confusion_matrix, axis=1) - TP
        f1 = 2 * TP / (2 * TP + FP + FN + 1e-6)
        return np.nanmean(f1), f1

    def add_batch(self, gt_image, pre_image):
        # âš ï¸ å…³é”®ä¿®æ”¹ï¼šåªå¤„ç† 0, 1, 2 çš„åƒç´ ï¼Œå¿½ç•¥ 255
        mask = (gt_image >= 0) & (gt_image < self.num_class)
        label = self.num_class * gt_image[mask].astype('int') + pre_image[mask]
        count = np.bincount(label, minlength=self.num_class**2)
        self.confusion_matrix += count.reshape(self.num_class, self.num_class)

    def reset(self):
        self.confusion_matrix = np.zeros((self.num_class,) * 2)

# ==========================================
# ğŸ“ 2. æ—¥å¿—ç³»ç»Ÿ
# ==========================================
def setup_logger(save_dir):
    os.makedirs(save_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = os.path.join(save_dir, f'train_log_{timestamp}.txt')
    
    logger = logging.getLogger("MSUNet_Train")
    logger.setLevel(logging.INFO)
    if logger.hasHandlers(): logger.handlers.clear()

    fh = logging.FileHandler(log_file, mode='a')
    fh.setFormatter(logging.Formatter('%(asctime)s | %(message)s'))
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter('%(message)s'))
    
    logger.addHandler(fh)
    logger.addHandler(ch)
    return logger

# ==========================================
# ğŸš€ 3. æ¨¡å‹åŒ…è£… (é€‚é…è¾“å…¥å‚æ•°)
# ==========================================
class MSFusion(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.model = MSFusionModel(in_channels=in_channels, num_classes=num_classes, norm_type='bn', dilation=2)
    def forward(self, x):
        return self.model(x)

# ==========================================
# ğŸ”¥ 4. è®­ç»ƒä¸»ç¨‹åº
# ==========================================
def train():
    # --- A. é…ç½®å‚æ•° (ç›´æ¥å†™åœ¨è¿™é‡Œé˜²æ­¢æ‰¾ä¸åˆ° yaml) ---
    cfg = {
        'data_root': "/media/cclsol/Chen/Lawin/LWViTs-for-weedmapping/dataset/processed",
        'train_split': "/media/cclsol/df07c0f4-31b8-4090-8a4a-8c254d91c123/ch/MSU-Net/MSU-Net/code/splits/train.txt",
        'val_split': "/media/cclsol/df07c0f4-31b8-4090-8a4a-8c254d91c123/ch/MSU-Net/MSU-Net/code/splits/test.txt", # ç¡®è®¤æ–‡ä»¶å
        'num_classes': 3,
        'batch_size': 4,       # æ˜¾å­˜ä¸å¤Ÿæ”¹ 2
        'lr': 0.0001,
        'epochs': 100,
        'save_dir': os.path.join(project_root, "checkpoints", "Eschikon_Run")
    }

    # --- B. åˆå§‹åŒ– ---
    logger = setup_logger(cfg['save_dir'])
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"ğŸš€ å¯åŠ¨è®­ç»ƒ | è®¾å¤‡: {device}")

    # --- C. æ•°æ®é›† ---
    logger.info("ğŸ”„ åŠ è½½æ•°æ®é›†...")
    train_dataset = EschikonDataset(cfg['data_root'], cfg['train_split'])
    val_dataset = EschikonDataset(cfg['data_root'], cfg['val_split'])

    train_loader = DataLoader(train_dataset, batch_size=cfg['batch_size'], shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=cfg['batch_size'], shuffle=False, num_workers=4)
    
    logger.info(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} | éªŒè¯é›†: {len(val_dataset)}")

    # --- D. æ¨¡å‹ ---
    # 5é€šé“: RGB(3) + NIR(1) + RE(1)
    model = MSFusion(in_channels=5, num_classes=cfg['num_classes']).to(device)

    # --- E. æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨ ---
    weights = torch.tensor([1.0, 3.0, 8.0]).to(device)
    criterion = nn.CrossEntropyLoss(weight=weights, ignore_index=255)
    
    optimizer = optim.Adam(model.parameters(), lr=cfg['lr'])
    
    # ğŸŸ¢ æ–°å¢ï¼šå­¦ä¹ ç‡è°ƒåº¦å™¨
    # patience=5: å¦‚æœ 5 ä¸ª Epoch éªŒè¯é›† Loss æ²¡ä¸‹é™ï¼Œå°±é™å­¦ä¹ ç‡
    # factor=0.1: é™ä½ä¸ºåŸæ¥çš„ 1/10
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='min', 
        factor=0.1, 
        patience=5, 
        verbose=True
    )
    
    evaluator = Evaluator(cfg['num_classes'])
    best_f1 = 0.0

    # --- F. å¾ªç¯ ---
   # ... åœ¨å¾ªç¯å†…éƒ¨ ...
    for epoch in range(cfg['epochs']):
        model.train()
        train_loss = 0
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{cfg['epochs']} [Train]")
        
        # ğŸŸ¢ æ–°å¢ï¼šæ·»åŠ ä¸€ä¸ªæ ‡å¿—ä½ï¼Œåªæ£€æŸ¥æ¯ä¸ª Epoch çš„ç¬¬ä¸€ä¸ª Batch
        check_first_batch = True 

        for images, masks in loop:
            images, masks = images.to(device), masks.to(device)

            # Mask æ¸…æ´—
            masks[(masks > 2) & (masks != 255)] = 255

            # ğŸŸ¢ æ–°å¢ï¼šæ‰“å°å½“å‰ Batch çš„ Mask æ•°å€¼æƒ…å†µ
            if check_first_batch:
                unique_vals = torch.unique(masks)
                print(f"\nğŸ” [DEBUG] å½“å‰ Batch Mask åŒ…å«æ•°å€¼: {unique_vals.cpu().tolist()}")
                # æ­£å¸¸åº”è¯¥çœ‹åˆ°: [0, 1, 2, 255] æˆ–è€…è‡³å°‘ [0, 1] æˆ– [0, 2]
                # å¦‚æœåªçœ‹åˆ° [0, 255]ï¼Œè¯´æ˜æ•°æ®åŠ è½½æœ‰é—®é¢˜ï¼
                check_first_batch = False

            outputs = model(images)
            # ... åé¢çš„ä¿æŒä¸å˜ ...
            loss = criterion(outputs, masks)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            loop.set_postfix(loss=f"{loss.item():.4f}")

        # --- éªŒè¯ ---
        model.eval()
        val_loss = 0
        evaluator.reset()
        
        with torch.no_grad():
            for images, masks in tqdm(val_loader, desc=f"Epoch {epoch+1} [Val]"):
                images, masks = images.to(device), masks.to(device)
                
                # åŒæ ·éœ€è¦æ¸…æ´—éªŒè¯é›† Mask
                masks[(masks > 2) & (masks != 255)] = 255

                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item()

                preds = torch.argmax(outputs, dim=1)
                evaluator.add_batch(masks.cpu().numpy(), preds.cpu().numpy())

        # --- æŒ‡æ ‡è®¡ç®— ---
        mIoU, class_iou = evaluator.mean_intersection_over_union()
        mF1, class_f1 = evaluator.f1_score()
        avg_train = train_loss / len(train_loader)
        avg_val = val_loss / len(val_loader)

        # æ—¥å¿—è¾“å‡º
        # Class 0:èƒŒæ™¯, 1:ä½œç‰©, 2:æ‚è‰
        log_msg = (
            f"\nğŸ“Š Ep {epoch+1} Result:\n"
            f"   Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f}\n"
            f"   mIoU: {mIoU:.2%} | mF1: {mF1:.2%}\n"
            f"   [F1 Detail] Crop: {class_f1[1]:.2%} | Weed: {class_f1[2]:.2%} (ç›®æ ‡)"
        )
        logger.info(log_msg)

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹ (ä¾æ® æ‚è‰F1 æˆ– mF1)
        # è¿™é‡Œæˆ‘è®¾ä¸ºä¾æ® mF1ï¼Œä½ ä¹Ÿå¯ä»¥æ”¹æˆ class_f1[2]
        if mF1 > best_f1:
            best_f1 = mF1
            save_path = os.path.join(cfg['save_dir'], "best_model.pth")
            torch.save(model.state_dict(), save_path)
            logger.info(f"ğŸŒŸ æ–°é«˜! æ¨¡å‹å·²ä¿å­˜: {save_path}")

if __name__ == '__main__':
    train()
