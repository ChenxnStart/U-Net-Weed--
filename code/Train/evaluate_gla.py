import os
import torch
import numpy as np
import cv2
import yaml
import sys

# è·¯å¾„å¯¼èˆª
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from data.gal_dataset import MyDatasetInterface
from train_gal import MSFusion  # ç¡®ä¿èƒ½å¼•ç”¨åˆ°ä½ çš„æ¨¡å‹åŒ…è£…ç±»

def visualize():
    # 1. é…ç½®ä¸æ¨¡å‹åŠ è½½
    config_path = os.path.join(project_root, "Params/Gal/gal_unet_v2.yaml")
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)['parameters']
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    num_classes = config['dataset']['num_classes'][0]
    
    # è‡ªåŠ¨å®šä½æœ€ä¼˜æƒé‡
    dataset_name = os.path.basename(config['dataset']['root'][0])
    model_path = os.path.join(project_root, "Checkpoints", dataset_name, "best_model_gal.pth")
    
    # åˆå§‹åŒ–æ¨¡å‹ (ç¡®ä¿è¾“å…¥é€šé“æ•°æ­£ç¡®ï¼Œè¿™é‡Œæ ¹æ®é…ç½®åŠ¨æ€è®¡ç®—)
    channels = config['dataset']['channels'][0]
    in_channels = sum([3 if c.lower() == 'rgb' else 1 for c in channels])
    
    model = MSFusion(in_channels=in_channels, num_classes=num_classes).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # 2. å‡†å¤‡æ•°æ®
    data_interface = MyDatasetInterface(config['dataset'])
    data_interface.build_data_loaders()
    
    # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
    vis_save_dir = os.path.join(project_root, "VIS_Results", dataset_name)
    os.makedirs(vis_save_dir, exist_ok=True)

    # å®šä¹‰é¢œè‰²æ˜ å°„ (BGRæ ¼å¼): [0:é»‘è‰²(èƒŒæ™¯), 1:ç»¿è‰²(ä½œç‰©), 2:çº¢è‰²(æ‚è‰)]
    colors = np.array([[0, 0, 0], [0, 255, 0], [0, 0, 255]], dtype='uint8')

    print(f"ğŸ§ æ­£åœ¨ä»éªŒè¯é›†ä¸­æå–å›¾ç‰‡è¿›è¡Œå¯è§†åŒ–...")

    with torch.no_grad():
        # å– 5 å¼ å›¾çœ‹æ•ˆæœ
        for i, (imgs, masks) in enumerate(data_interface.val_loader):
            if i >= 5: break 
            
            imgs, masks = imgs.to(device), masks.to(device)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)

            for j in range(imgs.size(0)):
                # 1. æå–å¹¶è½¬æ¢ RGB å›¾åƒ
                # æ³¨æ„ï¼šimgs æ˜¯ [B, C, H, W]ï¼Œå–å‡ºçš„å•å¼ æ˜¯ [C, H, W]
                img_tensor = imgs[j, :3, :, :]
                img_rgb = img_tensor.permute(1, 2, 0).cpu().numpy() # å˜ä¸º [H, W, 3]
                
                # åå½’ä¸€åŒ–ï¼šå‡è®¾è®­ç»ƒæ—¶é™¤ä»¥äº† 255
                img_rgb = (img_rgb * 255).astype('uint8')
                # OpenCV é»˜è®¤ä½¿ç”¨ BGRï¼Œæ‰€ä»¥è¦è½¬æ¢ä¸€ä¸‹é¢œè‰²ç©ºé—´
                img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                # 2. å‡†å¤‡ GT å’Œ Pred çš„å½©è‰²æ©è†œ
                gt_np = masks[j].cpu().numpy().astype('int')
                pred_np = preds[j].cpu().numpy().astype('int')
                
                gt_color = colors[gt_np]
                pred_color = colors[pred_np]

                # 3. æ¨ªå‘æ‹¼æ¥å¹¶ä¿å­˜
                combined = np.hstack([img_rgb, gt_color, pred_color])
                # ç”»ä¸Šæ–‡å­—æ ‡æ³¨
                cv2.putText(combined, "Original RGB", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                cv2.putText(combined, "Ground Truth", (512 + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                cv2.putText(combined, "Prediction", (1024 + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

                save_path = os.path.join(vis_save_dir, f"result_batch{i}_idx{j}.png")
                cv2.imwrite(save_path, combined)

    print(f"âœ… å¯è§†åŒ–å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {vis_save_dir}")

if __name__ == '__main__':
    visualize()
