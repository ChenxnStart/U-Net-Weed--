import os
import sys

# --- 1. æ ¸å¿ƒè·¯å¾„ä¿®æ­£ (å¿…é¡»æ”¾åœ¨æœ€å‰é¢) ---
# è·å–å½“å‰æ–‡ä»¶ (predict_vis_red.py) çš„ç»å¯¹è·¯å¾„
current_file_path = os.path.abspath(__file__)
# è·å–å…¶æ‰€åœ¨çš„ Train ç›®å½•
current_dir = os.path.dirname(current_file_path)
# è·å– Train çš„çˆ¶ç›®å½•ï¼Œå³ code ç›®å½•
project_root = os.path.dirname(current_dir)

# å°† code ç›®å½•åŠ å…¥ç³»ç»Ÿè·¯å¾„ï¼Œè¿™æ · Python å°±èƒ½çœ‹è§ MODEL å’Œ data äº†
if project_root not in sys.path:
    sys.path.append(project_root)

# --- 2. ç°åœ¨å†è¿›è¡ŒåŸæœ¬çš„ import ---
import cv2
import torch
import numpy as np
import matplotlib.pyplot as plt
from MODEL.model import MSFusionUNet as MSFusionModel
from data.rededge_dataset import EschikonDataset

# --- 1. é…ç½®è·¯å¾„ ---
# æŒ‡å‘åˆšæ‰ä¿å­˜çš„ best_model.pth
best_model_path = "/media/cclsol/df07c0f4-31b8-4090-8a4a-8c254d91c123/ch/MSU-Net/U-Net-v2/code/checkpoints/Eschikon_loss/best_model.pth"
data_root = "/media/cclsol/Chen/Lawin/LWViTs-for-weedmapping/dataset/processed"
test_split = "/media/cclsol/df07c0f4-31b8-4090-8a4a-8c254d91c123/ch/MSU-Net/MSU-Net/code/splits/val.txt"
save_dir = "vis_results"

os.makedirs(save_dir, exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- 2. é¢œè‰²å®šä¹‰ (ä¸ä½ çš„ Label ä¸€è‡´) ---
# 0:é»‘è‰² (èƒŒæ™¯), 1:ç»¿è‰² (ä½œç‰©), 2:çº¢è‰² (æ‚è‰)
PALETTE = np.array([
    [0, 0, 0],      # Background
    [0, 255, 0],    # Crop (Green)
    [255, 0, 0]     # Weed (Red)
], dtype=np.uint8)

def visualize():
    # åŠ è½½æ¨¡å‹
    # æ³¨æ„ï¼šå¦‚æœè®­ç»ƒæ—¶ç”¨äº†åŒ…è£…ç±» MSFusionï¼Œè¿™é‡ŒåŠ è½½éœ€è¦å¯¹åº”
    model = MSFusionModel(in_channels=5, num_classes=3)
    state_dict = torch.load(best_model_path, map_location=device)
    
    # ç§»é™¤ state_dict ä¸­çš„ 'model.' å‰ç¼€ (å¦‚æœä½ çš„åŒ…è£…ç±»é‡Œæœ‰è¿™ä¸ª)
    new_state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(new_state_dict)
    model.to(device)
    model.eval()

    # åŠ è½½æ•°æ®
    dataset = EschikonDataset(data_root, test_split)
    print(f"ğŸ¨ æ­£åœ¨ä»æµ‹è¯•é›†é€‰å–å›¾ç‰‡è¿›è¡Œå¯è§†åŒ–...")

    # éšæœºé€‰ 10 å¼ 
    for i in range(10):
        img_tensor, mask_tensor = dataset[i]
        
        # æ¨ç†
        input_tensor = img_tensor.unsqueeze(0).to(device)
        with torch.no_grad():
            output = model(input_tensor)
            pred = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

        # å‡†å¤‡å›¾åƒæ˜¾ç¤º
        # 1. åŸå§‹ RGB (å‰3é€šé“)
        rgb = img_tensor[:3, :, :].permute(1, 2, 0).numpy() * 255
        rgb = rgb.astype(np.uint8)
        
        # 2. çœŸå®æ ‡ç­¾ä¸Šè‰²
        gt_color = PALETTE[mask_tensor.numpy()]
        
        # 3. é¢„æµ‹ç»“æœä¸Šè‰²
        pred_color = PALETTE[pred]

        # 4. å åŠ å¯¹æ¯”å›¾ (Overlay)
        overlay = cv2.addWeighted(rgb, 0.7, pred_color, 0.3, 0)

        # ç»˜å›¾
        plt.figure(figsize=(20, 5))
        images = [rgb, gt_color, pred_color, overlay]
        titles = ['Original RGB', 'Ground Truth', 'Prediction', 'Overlay']
        
        for j in range(4):
            plt.subplot(1, 4, j+1)
            plt.imshow(images[j])
            plt.title(titles[j])
            plt.axis('off')

        save_path = os.path.join(save_dir, f"sample_{i}.png")
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ä¿å­˜: {save_path}")

if __name__ == '__main__':
    visualize()
